{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a86ca27-c61a-4157-9102-761f9e54fac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tyron\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, RepeatVector, TimeDistributed, Dense, BatchNormalization, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(x_train, _), (x_test, _) = cifar10.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "x_train_lstm = x_train.reshape(-1, 32 * 32, 3)\n",
    "x_test_lstm = x_test.reshape(-1, 32 * 32, 3)\n",
    "\n",
    "lstm_autoencoder = Sequential([\n",
    "    # Encoder\n",
    "    LSTM(128, activation='relu', input_shape=(32 * 32, 3), return_sequences=False),\n",
    "    RepeatVector(32 * 32),\n",
    "    # Decoder\n",
    "    LSTM(128, activation='relu', return_sequences=True),\n",
    "    TimeDistributed(Dense(3, activation='sigmoid')) \n",
    "])\n",
    "\n",
    "lstm_autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "lstm_autoencoder.fit(x_train_lstm, x_train_lstm, epochs=5, batch_size=128, validation_split=0.2)\n",
    "\n",
    "lstm_reconstructed = lstm_autoencoder.predict(x_test_lstm)\n",
    "\n",
    "n = 10  \n",
    "plt.figure(figsize=(20, 4))\n",
    "\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i])\n",
    "    plt.title(\"Original\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(lstm_reconstructed[i].reshape(32, 32, 3))\n",
    "    plt.title(\"LSTM Reconstructed\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59083eb9-974c-4066-bb83-d73a460ac6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, UpSampling2D, SimpleRNN, TimeDistributed, RepeatVector, LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(x_train, _), (x_test, _) = cifar10.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "x_train_rnn = x_train.reshape(-1, 32, 32)\n",
    "x_test_rnn = x_test.reshape(-1, 32, 32)\n",
    "\n",
    "\n",
    "lstm_autoencoder = Sequential([\n",
    "    # Encoder\n",
    "    LSTM(128, activation='relu', input_shape=(32, 32), return_sequences=False),\n",
    "    RepeatVector(32),\n",
    "    # Decoder\n",
    "    LSTM(128, activation='relu', return_sequences=True),\n",
    "    TimeDistributed(Dense(32, activation='sigmoid'))\n",
    "])\n",
    "\n",
    "lstm_autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "print(\"\\nLSTM Autoencoder Summary:\")\n",
    "lstm_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98222c0-06c9-491f-8d27-e5d6086c075d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, UpSampling2D, Reshape, SimpleRNN, TimeDistributed, RepeatVector\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(x_train, _), (x_test, _) = cifar10.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "x_train_cnn = x_train.reshape(-1, 32, 32, 3)  \n",
    "x_test_cnn = x_test.reshape(-1, 32, 32, 3)   \n",
    "x_train_rnn = x_train.reshape(-1, 32, 32 * 3)  \n",
    "x_test_rnn = x_test.reshape(-1, 32, 32 * 3)    \n",
    "\n",
    "cnn_autoencoder = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2), padding='same'),\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    UpSampling2D(size=(2, 2)),\n",
    "    Conv2D(3, kernel_size=(3, 3), activation='sigmoid', padding='same')  \n",
    "])\n",
    "\n",
    "cnn_autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "cnn_autoencoder.fit(x_train_cnn, x_train_cnn, epochs=10, batch_size=128, validation_split=0.2)\n",
    "\n",
    "rnn_autoencoder = Sequential([\n",
    "    SimpleRNN(128, activation='relu', input_shape=(32, 96), return_sequences=False), \n",
    "    RepeatVector(32), \n",
    "    SimpleRNN(128, activation='relu', return_sequences=True),\n",
    "    TimeDistributed(Dense(96, activation='sigmoid')) \n",
    "])\n",
    "\n",
    "rnn_autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "rnn_autoencoder.fit(x_train_rnn, x_train_rnn, epochs=10, batch_size=128, validation_split=0.2)\n",
    "\n",
    "cnn_reconstructed = cnn_autoencoder.predict(x_test_cnn)\n",
    "rnn_reconstructed = rnn_autoencoder.predict(x_test_rnn)\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i])\n",
    "    plt.title(\"Original\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(cnn_reconstructed[i])\n",
    "    plt.title(\"CNN Reconstructed\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i])\n",
    "    plt.title(\"Original\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(rnn_reconstructed[i].reshape(32, 32, 3))  \n",
    "    plt.title(\"RNN Reconstructed\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1755891c-5d02-407f-b9a1-e91f7f49c66e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
